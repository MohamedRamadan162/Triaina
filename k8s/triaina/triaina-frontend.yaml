apiVersion: apps/v1
kind: Deployment
metadata:
  name: triaina-frontend
  namespace: triaina
  labels:
    app: triaina-frontend
spec:
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1 # Create max one extra pod at a time to roll an update to
      maxUnavailable: 0 # No down pods
  selector:
    matchLabels:
      app: triaina-frontend
  template:
    metadata:
      labels:
        app: triaina-frontend
    spec:
      imagePullSecrets:
        - name: ghcr-secret
      containers:
        - name: triaina-frontend
          image: ghcr.io/ossamatammam/triaina-frontend:latest
          resources:
            requests:
              memory: "64Mi"
              cpu: "250m"
            limits:
              memory: "1Gi"
              cpu: "500m"
          ports:
            - containerPort: 3000
      ## Spread out our pods across different zones
      affinity:
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            ## Different AZs for higher availability
            - weight: 100
              podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app: triaina-frontend
                topologyKey: kubernetes.io/zone
            ## Different nodes for fault tolerance and parallelism on the machine
            - weight: 70
              podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app: triaina-frontend
                topologyKey: kubernetes.io/hostname
---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: triaina-frontend-hpa
  namespace: triaina
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: triaina-frontend
  minReplicas: 1
  maxReplicas: 10
  metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 80
  behavior:
    ## React instantly to high loads
    scaleUp:
      stabilizationWindowSeconds: 0
      policies:
        - type: Percent
          value: 100
          periodSeconds: 15
        - type: Pods
          value: 4 # But not more than 4 at once
          periodSeconds: 15
      selectPolicy: Max
    ## Wait 5 minutes before scaling down in case high load continues in these 5 minutes
    scaleDown:
      stabilizationWindowSeconds: 300
      policies:
        - type: Percent
          value: 100
          periodSeconds: 30
        - type: Pods
          value: 2 # But not more than 2 at once
          periodSeconds: 30
      selectPolicy: Min # Use whichever removes fewer pods
---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: triaina-frontend-pdb
  namespace: triaina
spec:
  minAvailable: "0%"
  selector:
    matchLabels:
      app: triaina-frontend
---
apiVersion: v1
kind: Service
metadata:
  name: triaina-frontend-service
  namespace: triaina
  labels:
    app: triaina-frontend
spec:
  type: ClusterIP
  selector:
    app: triaina-frontend
  ports:
    - name: http
      port: 80 # Port exposed by the service
      targetPort: 3000 # Port exposed by the pod to the service (Rails Port)
  sessionAffinity: None # We may use this if we want sticky sessions (if state arises)
